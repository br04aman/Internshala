{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["# Advanced Visualizations: Trading Patterns and Market Sentiment"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","from scipy import stats\n","\n","# Set style for matplotlib/seaborn plots\n","plt.style.use('fivethirtyeight')\n","sns.set_palette('viridis')\n","\n","# Read the data\n","df = pd.read_csv('merged_data.csv')\n","\n","# Display first few rows\n","df.head()"]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## Data Preparation"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["# Convert timestamp to datetime\n","df['Date'] = pd.to_datetime(df['Timestamp'])\n","\n","# Create sentiment categories\n","df['Sentiment_Category'] = pd.cut(df['value'], \n","                                  bins=[0, 25, 50, 75, 100],\n","                                  labels=['Extreme Fear', 'Fear', 'Neutral', 'Greed'])\n","\n","# Calculate daily metrics\n","daily_data = df.groupby(['Date']).agg({\n","    'Closed PnL': 'sum',\n","    'Size USD': 'sum',\n","    'Trade ID': 'count',\n","    'value': 'first',\n","    'Sentiment_Category': 'first'\n","}).reset_index()\n","\n","# Calculate rolling metrics (7-day window)\n","daily_data['Rolling_PnL'] = daily_data['Closed PnL'].rolling(window=7).mean()\n","daily_data['Rolling_Volume'] = daily_data['Size USD'].rolling(window=7).mean()\n","daily_data['Rolling_Frequency'] = daily_data['Trade ID'].rolling(window=7).mean()\n","\n","# Calculate volatility (standard deviation of PnL over 7-day window)\n","daily_data['PnL_Volatility'] = daily_data['Closed PnL'].rolling(window=7).std()\n","\n","# Drop NaN values from rolling calculations\n","daily_data_clean = daily_data.dropna()\n","\n","daily_data_clean.head()"]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## 1. Interactive Time Series Dashboard"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["# Create interactive time series dashboard with Plotly\n","fig = make_subplots(rows=4, cols=1, \n","                    shared_xaxes=True,\n","                    vertical_spacing=0.05,\n","                    subplot_titles=('Profitability (PnL)', 'Trading Volume', \n","                                    'Trade Frequency', 'Fear & Greed Index'))\n","\n","# Add PnL trace\n","fig.add_trace(\n","    go.Scatter(x=daily_data_clean['Date'], y=daily_data_clean['Closed PnL'],\n","              mode='lines', name='Daily PnL',\n","              line=dict(color='rgba(50, 171, 96, 0.6)')),\n","    row=1, col=1\n",")\n","\n","fig.add_trace(\n","    go.Scatter(x=daily_data_clean['Date'], y=daily_data_clean['Rolling_PnL'],\n","              mode='lines', name='7-Day Avg PnL',\n","              line=dict(color='rgba(50, 171, 96, 1)', width=3)),\n","    row=1, col=1\n",")\n","\n","# Add Volume trace\n","fig.add_trace(\n","    go.Bar(x=daily_data_clean['Date'], y=daily_data_clean['Size USD'],\n","           name='Daily Volume', marker_color='rgba(58, 71, 80, 0.6)'),\n","    row=2, col=1\n",")\n","\n","fig.add_trace(\n","    go.Scatter(x=daily_data_clean['Date'], y=daily_data_clean['Rolling_Volume'],\n","              mode='lines', name='7-Day Avg Volume',\n","              line=dict(color='rgba(246, 78, 139, 1)', width=3)),\n","    row=2, col=1\n",")\n","\n","# Add Trade Frequency trace\n","fig.add_trace(\n","    go.Bar(x=daily_data_clean['Date'], y=daily_data_clean['Trade ID'],\n","           name='Daily Trades', marker_color='rgba(246, 78, 139, 0.6)'),\n","    row=3, col=1\n",")\n","\n","fig.add_trace(\n","    go.Scatter(x=daily_data_clean['Date'], y=daily_data_clean['Rolling_Frequency'],\n","              mode='lines', name='7-Day Avg Trades',\n","              line=dict(color='rgba(58, 71, 80, 1)', width=3)),\n","    row=3, col=1\n",")\n","\n","# Add Fear & Greed Index trace with color scale\n","fig.add_trace(\n","    go.Scatter(x=daily_data_clean['Date'], y=daily_data_clean['value'],\n","              mode='lines+markers', name='Fear & Greed Index',\n","              marker=dict(\n","                  size=8,\n","                  color=daily_data_clean['value'],\n","                  colorscale='RdYlGn',\n","                  showscale=True,\n","                  colorbar=dict(title='Sentiment')\n","              ),\n","              line=dict(color='rgba(0, 0, 0, 0.3)')),\n","    row=4, col=1\n",")\n","\n","# Add sentiment category background colors\n","for i, category in enumerate(['Extreme Fear', 'Fear', 'Neutral', 'Greed']):\n","    category_data = daily_data_clean[daily_data_clean['Sentiment_Category'] == category]\n","    if not category_data.empty:\n","        for date in category_data['Date']:\n","            date_str = date.strftime('%Y-%m-%d')\n","            colors = ['rgba(255, 0, 0, 0.1)', 'rgba(255, 165, 0, 0.1)', \n","                      'rgba(255, 255, 0, 0.1)', 'rgba(0, 128, 0, 0.1)']\n","            fig.add_vrect(\n","                x0=date_str, x1=date_str,\n","                fillcolor=colors[i],\n","                opacity=0.5,\n","                layer='below',\n","                line_width=0\n","            )\n","\n","# Update layout\n","fig.update_layout(\n","    height=900,\n","    width=1000,\n","    title_text='Interactive Trading Metrics Dashboard',\n","    showlegend=True,\n","    legend=dict(orientation='h', y=1.02),\n","    hovermode='x unified'\n",")\n","\n","# Update y-axes labels\n","fig.update_yaxes(title_text='PnL', row=1, col=1)\n","fig.update_yaxes(title_text='Volume (USD)', row=2, col=1)\n","fig.update_yaxes(title_text='Number of Trades', row=3, col=1)\n","fig.update_yaxes(title_text='Fear & Greed Index', row=4, col=1)\n","\n","fig.show()"]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## 2. Sentiment Transition Analysis"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["# Identify sentiment transitions
daily_data_clean['Prev_Sentiment'] = daily_data_clean['Sentiment_Category'].shift(1)
# Convert categorical variables to strings before concatenation
daily_data_clean['Sentiment_Transition'] = daily_data_clean['Prev_Sentiment'].astype(str) + ' â†’ ' + daily_data_clean['Sentiment_Category'].astype(str)

# Remove rows with NaN transitions (first row)
transition_data = daily_data_clean.dropna(subset=['Prev_Sentiment'])\n","\n","# Calculate average metrics for each transition type\n","transition_metrics = transition_data.groupby('Sentiment_Transition').agg({\n","    'Closed PnL': 'mean',\n","    'Size USD': 'mean',\n","    'Trade ID': 'mean',\n","    'PnL_Volatility': 'mean'\n","}).reset_index()\n","\n","# Create a heatmap of transitions\n","# First, create a pivot table of transition counts\n","transition_counts = pd.crosstab(transition_data['Prev_Sentiment'], \n","                               transition_data['Sentiment_Category'])\n","\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(transition_counts, annot=True, cmap='YlGnBu', fmt='d', cbar_kws={'label': 'Frequency'})\n","plt.title('Sentiment Transition Frequency', fontsize=16, pad=20)\n","plt.xlabel('To Sentiment', fontsize=12)\n","plt.ylabel('From Sentiment', fontsize=12)\n","plt.tight_layout()\n","plt.show()\n","\n","# Create a visualization of PnL by transition type\n","plt.figure(figsize=(14, 8))\n","\n","# Sort by PnL for better visualization\n","transition_metrics_sorted = transition_metrics.sort_values('Closed PnL')\n","\n","# Create color mapping based on PnL values\n","colors = plt.cm.RdYlGn(np.linspace(0, 1, len(transition_metrics_sorted)))\n","\n","bars = plt.bar(transition_metrics_sorted['Sentiment_Transition'], \n","        transition_metrics_sorted['Closed PnL'],\n","        color=colors)\n","\n","plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n","plt.title('Average PnL by Sentiment Transition', fontsize=16, pad=20)\n","plt.xlabel('Sentiment Transition', fontsize=12)\n","plt.ylabel('Average PnL', fontsize=12)\n","plt.xticks(rotation=45, ha='right')\n","plt.grid(axis='y', alpha=0.3)\n","\n","# Add value labels on top of bars\n","for bar in bars:\n","    height = bar.get_height()\n","    plt.text(bar.get_x() + bar.get_width()/2., height + (0.1 if height >= 0 else -0.1),\n","             f'{height:.2f}',\n","             ha='center', va='bottom' if height >= 0 else 'top', fontsize=9)\n","\n","plt.tight_layout()\n","plt.show()"]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## 3. Risk-Return Analysis by Sentiment"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["# Calculate risk-adjusted returns (Sharpe ratio proxy)\n","# Using PnL as return and PnL volatility as risk\n","daily_data_clean['Risk_Adjusted_Return'] = daily_data_clean['Closed PnL'] / daily_data_clean['PnL_Volatility'].replace(0, np.nan)\n","\n","# Create scatter plot of risk vs. return by sentiment\n","plt.figure(figsize=(12, 10))\n","\n","# Define colors for sentiment categories\n","colors = {'Extreme Fear': 'red', 'Fear': 'orange', 'Neutral': 'yellow', 'Greed': 'green'}\n","\n","# Create scatter plot\n","for sentiment in daily_data_clean['Sentiment_Category'].unique():\n","    subset = daily_data_clean[daily_data_clean['Sentiment_Category'] == sentiment]\n","    plt.scatter(subset['PnL_Volatility'], subset['Closed PnL'], \n","                label=sentiment, color=colors[sentiment], alpha=0.7, s=80)\n","\n","# Add quadrant lines\n","plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n","plt.axvline(x=daily_data_clean['PnL_Volatility'].median(), color='black', linestyle='-', alpha=0.3)\n","\n","# Add quadrant labels\n","plt.text(daily_data_clean['PnL_Volatility'].max()*0.75, daily_data_clean['Closed PnL'].max()*0.75, \n","         'High Risk, High Return', fontsize=12, ha='center')\n","plt.text(daily_data_clean['PnL_Volatility'].min()*1.5, daily_data_clean['Closed PnL'].max()*0.75, \n","         'Low Risk, High Return', fontsize=12, ha='center')\n","plt.text(daily_data_clean['PnL_Volatility'].max()*0.75, daily_data_clean['Closed PnL'].min()*0.75, \n","         'High Risk, Low Return', fontsize=12, ha='center')\n","plt.text(daily_data_clean['PnL_Volatility'].min()*1.5, daily_data_clean['Closed PnL'].min()*0.75, \n","         'Low Risk, Low Return', fontsize=12, ha='center')\n","\n","plt.title('Risk-Return Profile by Market Sentiment', fontsize=16, pad=20)\n","plt.xlabel('Risk (PnL Volatility)', fontsize=12)\n","plt.ylabel('Return (PnL)', fontsize=12)\n","plt.legend(title='Market Sentiment')\n","plt.grid(alpha=0.3)\n","plt.tight_layout()\n","plt.show()\n","\n","# Create a 3D scatter plot of Risk, Return, and Volume by sentiment\n","fig = px.scatter_3d(daily_data_clean, x='PnL_Volatility', y='Closed PnL', z='Size USD',\n","                   color='Sentiment_Category', size='Trade ID',\n","                   color_discrete_map={'Extreme Fear': 'red', 'Fear': 'orange', \n","                                        'Neutral': 'yellow', 'Greed': 'green'},\n","                   title='3D Risk-Return-Volume Analysis by Sentiment',\n","                   labels={'PnL_Volatility': 'Risk (PnL Volatility)', \n","                           'Closed PnL': 'Return (PnL)', \n","                           'Size USD': 'Volume (USD)',\n","                           'Trade ID': 'Number of Trades',\n","                           'Sentiment_Category': 'Market Sentiment'})\n","\n","fig.update_layout(scene=dict(xaxis_title='Risk', yaxis_title='Return', zaxis_title='Volume'),\n","                  width=900, height=700)\n","\n","fig.show()"]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## 4. Trading Pattern Clusters"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["# Select features for clustering\n","cluster_features = daily_data_clean[['Closed PnL', 'Size USD', 'Trade ID', 'value', 'PnL_Volatility']]\n","\n","# Normalize the data\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaled_features = scaler.fit_transform(cluster_features)\n","\n","# Perform K-means clustering\n","from sklearn.cluster import KMeans\n","kmeans = KMeans(n_clusters=4, random_state=42)\n","clusters = kmeans.fit_predict(scaled_features)\n","\n","# Add cluster labels to the dataframe\n","daily_data_clean['Cluster'] = clusters\n","\n","# Calculate cluster centers\n","cluster_centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), \n","                             columns=cluster_features.columns)\n","\n","# Create a radar chart to visualize cluster characteristics\n","# Prepare data for radar chart\n","categories = ['PnL', 'Volume', 'Frequency', 'Sentiment', 'Volatility']\n","\n","# Normalize cluster centers for radar chart\n","radar_data = cluster_centers.copy()\n","for col in radar_data.columns:\n","    radar_data[col] = (radar_data[col] - radar_data[col].min()) / (radar_data[col].max() - radar_data[col].min())\n","\n","# Create radar chart\n","fig = go.Figure()\n","\n","for i in range(len(radar_data)):\n","    fig.add_trace(go.Scatterpolar(\n","        r=[radar_data.iloc[i]['Closed PnL'], radar_data.iloc[i]['Size USD'], \n","           radar_data.iloc[i]['Trade ID'], radar_data.iloc[i]['value'], \n","           radar_data.iloc[i]['PnL_Volatility']],\n","        theta=categories,\n","        fill='toself',\n","        name=f'Cluster {i}'\n","    ))\n","\n","fig.update_layout(\n","    polar=dict(\n","        radialaxis=dict(\n","            visible=True,\n","            range=[0, 1]\n","        )),\n","    showlegend=True,\n","    title='Trading Pattern Clusters Characteristics'\n",")\n","\n","fig.show()\n","\n","# Create a scatter plot of clusters\n","plt.figure(figsize=(12, 8))\n","scatter = plt.scatter(daily_data_clean['value'], daily_data_clean['Closed PnL'], \n","                     c=daily_data_clean['Cluster'], cmap='viridis', \n","                     s=daily_data_clean['Size USD']/1000, alpha=0.7)\n","\n","plt.colorbar(scatter, label='Cluster')\n","plt.title('Trading Clusters by Sentiment and PnL', fontsize=16, pad=20)\n","plt.xlabel('Fear & Greed Index', fontsize=12)\n","plt.ylabel('PnL', fontsize=12)\n","plt.grid(alpha=0.3)\n","plt.tight_layout()\n","plt.show()\n","\n","# Calculate and display cluster statistics\n","cluster_stats = daily_data_clean.groupby('Cluster').agg({\n","    'Closed PnL': ['mean', 'std'],\n","    'Size USD': ['mean', 'std'],\n","    'Trade ID': ['mean', 'std'],\n","    'value': ['mean', 'std'],\n","    'PnL_Volatility': ['mean', 'std'],\n","    'Date': 'count'\n","}).round(2)\n","\n","# Rename count column to 'Days'\n","cluster_stats.columns = ['PnL_Mean', 'PnL_Std', 'Volume_Mean', 'Volume_Std', \n","                        'Frequency_Mean', 'Frequency_Std', 'Sentiment_Mean', 'Sentiment_Std',\n","                        'Volatility_Mean', 'Volatility_Std', 'Days']\n","\n","print('\nCluster Statistics:')\n","print(cluster_stats)"]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## 5. Predictive Indicators"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["# Calculate lagged features to identify predictive indicators\n","for lag in range(1, 6):  # Create 1 to 5 day lags\n","    daily_data_clean[f'Sentiment_Lag_{lag}'] = daily_data_clean['value'].shift(lag)\n","    daily_data_clean[f'Volume_Lag_{lag}'] = daily_data_clean['Size USD'].shift(lag)\n","    daily_data_clean[f'Frequency_Lag_{lag}'] = daily_data_clean['Trade ID'].shift(lag)\n","\n","# Drop rows with NaN values from lagging\n","lag_data = daily_data_clean.dropna()\n","\n","# Calculate correlations between lagged features and PnL\n","lag_correlations = pd.DataFrame(index=['Sentiment', 'Volume', 'Frequency'])\n","\n","for lag in range(1, 6):\n","    lag_correlations[f'Lag_{lag}'] = [\n","        lag_data[f'Sentiment_Lag_{lag}'].corr(lag_data['Closed PnL']),\n","        lag_data[f'Volume_Lag_{lag}'].corr(lag_data['Closed PnL']),\n","        lag_data[f'Frequency_Lag_{lag}'].corr(lag_data['Closed PnL'])\n","    ]\n","\n","# Create heatmap of lag correlations\n","plt.figure(figsize=(12, 6))\n","sns.heatmap(lag_correlations, annot=True, cmap='RdBu_r', center=0, fmt='.2f',\n","            cbar_kws={'label': 'Correlation with PnL'})\n","plt.title('Predictive Power of Lagged Indicators for PnL', fontsize=16, pad=20)\n","plt.xlabel('Lag (Days)', fontsize=12)\n","plt.ylabel('Indicator', fontsize=12)\n","plt.tight_layout()\n","plt.show()\n","\n","# Create a combined predictive indicator based on the strongest correlations\n","# For example, if Sentiment_Lag_2 and Volume_Lag_1 have the strongest correlations\n","# Find the strongest lag for each feature\n","strongest_lags = {}\n","for feature in ['Sentiment', 'Volume', 'Frequency']:\n","    feature_correlations = lag_correlations.loc[feature].abs()\n","    strongest_lag = feature_correlations.idxmax()\n","    strongest_lags[feature] = strongest_lag\n","\n","print('\nStrongest predictive lags:')\n","for feature, lag in strongest_lags.items():\n","    lag_value = lag_correlations.loc[feature, lag]\n","    print(f'{feature} {lag}: {lag_value:.2f}')\n","\n","# Create a combined indicator using the strongest lags\n","# Normalize each component first\n","for feature in ['Sentiment', 'Volume', 'Frequency']:\n","    lag_col = f'{feature}_Lag_{strongest_lags[feature].split(\"_\")[1]}'\n","    lag_data[f'{lag_col}_Norm'] = (lag_data[lag_col] - lag_data[lag_col].mean()) / lag_data[lag_col].std()\n","\n","# Create the combined indicator (weighted by correlation strength)\n","lag_data['Combined_Indicator'] = 0\n","for feature in ['Sentiment', 'Volume', 'Frequency']:\n","    lag_col = f'{feature}_Lag_{strongest_lags[feature].split(\"_\")[1]}'\n","    weight = abs(lag_correlations.loc[feature, strongest_lags[feature]])\n","    lag_data['Combined_Indicator'] += lag_data[f'{lag_col}_Norm'] * weight\n","\n","# Normalize the combined indicator\n","lag_data['Combined_Indicator'] = (lag_data['Combined_Indicator'] - lag_data['Combined_Indicator'].mean()) / lag_data['Combined_Indicator'].std()\n","\n","# Plot the combined indicator against PnL\n","plt.figure(figsize=(14, 8))\n","\n","# Create scatter plot\n","scatter = plt.scatter(lag_data['Combined_Indicator'], lag_data['Closed PnL'],\n","                     c=lag_data['value'], cmap='RdYlGn', alpha=0.7, s=80)\n","\n","# Add trend line\n","z = np.polyfit(lag_data['Combined_Indicator'], lag_data['Closed PnL'], 1)\n","p = np.poly1d(z)\n","plt.plot(lag_data['Combined_Indicator'], p(lag_data['Combined_Indicator']), \n","         'r--', linewidth=2, alpha=0.7)\n","\n","# Add correlation coefficient\n","corr = lag_data['Combined_Indicator'].corr(lag_data['Closed PnL'])\n","plt.annotate(f'Correlation: {corr:.2f}', \n","             xy=(0.05, 0.95), xycoords='axes fraction',\n","             fontsize=12, ha='left', va='top',\n","             bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.3))\n","\n","plt.colorbar(scatter, label='Fear & Greed Index')\n","plt.title('Combined Predictive Indicator vs PnL', fontsize=16, pad=20)\n","plt.xlabel('Combined Indicator (Normalized)', fontsize=12)\n","plt.ylabel('PnL', fontsize=12)\n","plt.grid(alpha=0.3)\n","plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n","plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n","plt.tight_layout()\n","plt.show()"]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["## 6. Trading Strategy Zones"]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ["# Create a visualization of optimal trading zones\n","# First, calculate success rate by sentiment and volume\n","\n","# Create sentiment and volume bins\n","df['Volume_Category'] = pd.qcut(df['Size USD'], 4, labels=['Low', 'Medium-Low', 'Medium-High', 'High'])\n","\n","# Calculate success rate (positive PnL percentage) by sentiment and volume\n","success_rate = df.groupby(['Sentiment_Category', 'Volume_Category']).apply(\n","    lambda x: (x['Closed PnL'] > 0).mean() * 100  # Percentage of positive PnL trades\n",").reset_index(name='Success_Rate')\n","\n","# Reshape for heatmap\n","success_pivot = success_rate.pivot(index='Sentiment_Category', \n","                                  columns='Volume_Category', \n","                                  values='Success_Rate')\n","\n","# Create heatmap of success rates\n","plt.figure(figsize=(12, 8))\n","sns.heatmap(success_pivot, annot=True, cmap='RdYlGn', fmt='.1f',\n","            cbar_kws={'label': 'Success Rate (%)'})\n","plt.title('Trading Success Rate by Sentiment and Volume', fontsize=16, pad=20)\n","plt.xlabel('Volume Category', fontsize=12)\n","plt.ylabel('Sentiment Category', fontsize=12)\n","plt.tight_layout()\n","plt.show()\n","\n","# Create a strategy map based on all metrics\n","# Calculate average metrics by sentiment and volume\n","strategy_metrics = df.groupby(['Sentiment_Category', 'Volume_Category']).agg({\n","    'Closed PnL': 'mean',\n","    'Trade ID': 'count',\n","    'Size USD': 'mean'\n","}).reset_index()\n","\n","# Merge with success rate\n","strategy_map = strategy_metrics.merge(success_rate, on=['Sentiment_Category', 'Volume_Category'])\n","\n","# Create a bubble chart of strategy zones\n","plt.figure(figsize=(14, 10))\n","\n","# Define sentiment order and colors\n","sentiment_order = ['Extreme Fear', 'Fear', 'Neutral', 'Greed']\n","sentiment_colors = {'Extreme Fear': 'red', 'Fear': 'orange', 'Neutral': 'yellow', 'Greed': 'green'}\n","\n","# Create a numeric x-axis for sentiment categories\n","sentiment_x = {'Extreme Fear': 1, 'Fear': 2, 'Neutral': 3, 'Greed': 4}\n","strategy_map['Sentiment_X'] = strategy_map['Sentiment_Category'].map(sentiment_x)\n","\n","# Create a numeric y-axis for volume categories\n","volume_y = {'Low': 1, 'Medium-Low': 2, 'Medium-High': 3, 'High': 4}\n","strategy_map['Volume_Y'] = strategy_map['Volume_Category'].map(volume_y)\n","\n","# Create bubble chart\n","for sentiment in sentiment_order:\n","    subset = strategy_map[strategy_map['Sentiment_Category'] == sentiment]\n","    plt.scatter(subset['Sentiment_X'], subset['Volume_Y'], \n","                s=subset['Success_Rate']*20,  # Size based on success rate\n","                c=subset['Closed PnL'],      # Color based on PnL\n","                cmap='RdYlGn', alpha=0.7,\n","                edgecolors='black', linewidths=1)\n","    \n","    # Add labels\n","    for i, row in subset.iterrows():\n","        plt.annotate(f\"{row['Success_Rate']:.1f}%\n{row['Closed PnL']:.2f}\",\n","                     (row['Sentiment_X'], row['Volume_Y']),\n","                     ha='center', va='center', fontsize=9)\n","\n","# Customize plot\n","plt.xticks([1, 2, 3, 4], sentiment_order)\n","plt.yticks([1, 2, 3, 4], ['Low', 'Medium-Low', 'Medium-High', 'High'])\n","plt.title('Trading Strategy Map: Success Rate and PnL by Zone', fontsize=16, pad=20)\n","plt.xlabel('Market Sentiment', fontsize=12)\n","plt.ylabel('Volume Category', fontsize=12)\n","plt.colorbar(label='Average PnL')\n","plt.grid(True, alpha=0.3)\n","\n","# Add strategy annotations\n","plt.annotate('MEAN REVERSION\nSTRATEGY',\n","             xy=(1, 4), xycoords='data',\n","             xytext=(0.5, 0.9), textcoords='axes fraction',\n","             arrowprops=dict(facecolor='black', shrink=0.05, width=2, headwidth=8),\n","             fontsize=12, ha='center', va='center',\n","             bbox=dict(boxstyle='round,pad=0.5', fc='lightblue', alpha=0.7))\n","\n","plt.annotate('MOMENTUM\nSTRATEGY',\n","             xy=(4, 3), xycoords='data',\n","             xytext=(0.8, 0.5), textcoords='axes fraction',\n","             arrowprops=dict(facecolor='black', shrink=0.05, width=2, headwidth=8),\n","             fontsize=12, ha='center', va='center',\n","             bbox=dict(boxstyle='round,pad=0.5', fc='lightgreen', alpha=0.7))\n","\n","plt.annotate('RANGE-BOUND\nSTRATEGY',\n","             xy=(3, 2), xycoords='data',\n","             xytext=(0.5, 0.3), textcoords='axes fraction',\n","             arrowprops=dict(facecolor='black', shrink=0.05, width=2, headwidth=8),\n","             fontsize=12, ha='center', va='center',\n","             bbox=dict(boxstyle='round,pad=0.5', fc='lightyellow', alpha=0.7))\n","\n","plt.tight_layout()\n","plt.show()"]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}